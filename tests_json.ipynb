{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giselesousar/msr_tests/blob/main/tests_json.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3SALni1FBRr"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiK9BT4-RfzQ",
        "outputId": "fe4ba2ed-3571-4a1f-9bac-0c569052384e"
      },
      "outputs": [],
      "source": [
        "!pip install pydriller"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "id": "77VaQQNwErx7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from enum import Enum\n",
        "from pydriller import Repository"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importa o banco de dados do Cassandra (commits de v3.0.0 até v.3.11.11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1n2RE3xsLtD-fv_omcI6vtm6x5si-PxmZ' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1n2RE3xsLtD-fv_omcI6vtm6x5si-PxmZ\" -O msrcassandra300to31111.db && rm -rf /tmp/cookies.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEAEYUjdGph5"
      },
      "source": [
        "# Global variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "id": "0dJXrweaGouH"
      },
      "outputs": [],
      "source": [
        "global repository_name\n",
        "global repository_url\n",
        "repository_name = 'cassandra'\n",
        "repository_url = 'https://github.com/apache/cassandra.git'\n",
        "\n",
        "class Type(Enum):\n",
        "  DIR = 0\n",
        "  FILE = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Carrega as tabelas do banco em dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carrega as tabelas do banco em dataframes\n",
        "\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "DATA_BASE='msrcassandra300to31111.db'\n",
        "con = sqlite3.connect(DATA_BASE)\n",
        "\n",
        "my_query_commits = \"select * from commitscomplete\"\n",
        "my_query_files = \"select * from filescomplete\"\n",
        "my_query_files_commits = \"select f.id as 'file_id', f.hash as 'file_hash_commit', f.description as 'file_description', f.is_java as 'file_is_java', f.created_date as 'file_created_date', f.old_path as 'file_old_path', f.new_path as 'file_new_path', f.filename as 'file_filename', f.change_type as 'file_change_type', f.diff as 'file_diff', f.diff_parsed as 'file_diff_parsed', f.added_lines as 'file_added_lines', f.deleted_lines as 'file_deleted_lines', f.source_code as 'file_source_code', f.source_code_before as 'file_source_code_before', f.nloc as 'file_nloc', f.complexity as 'file_complexity', f.token_count as 'file_token_count', f.commit_id as 'file_commit_id', c.* from filescomplete f, commitscomplete c where f.commit_id=c.id\"\n",
        "\n",
        "df_commits_from_db = pd.read_sql_query(my_query_commits, con)\n",
        "df_files_from_db = pd.read_sql_query(my_query_files, con)\n",
        "df_files_commits_from_db = pd.read_sql(my_query_files_commits, con)\n",
        "\n",
        "con.close() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_files_from_db['modified_lines'] = df_files_from_db.added_lines + df_files_from_db.deleted_lines\n",
        "df_files_commits_from_db['modified_lines'] = df_files_commits_from_db.file_added_lines + df_files_commits_from_db.file_deleted_lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_files_from_db.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_files_commits_from_db.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y4n7ZGGFDSC"
      },
      "source": [
        "# Clone repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOUHeTM8LRJ-",
        "outputId": "71582b2e-03f8-4742-bbbf-801f58810dee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Remove diretório antigo\n",
            "Cloning into 'promocity'...\n",
            "remote: Enumerating objects: 841, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 841 (delta 10), reused 21 (delta 2), pack-reused 798\u001b[K\n",
            "Receiving objects: 100% (841/841), 4.00 MiB | 13.65 MiB/s, done.\n",
            "Resolving deltas: 100% (324/324), done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tree is already the newest version (1.7.0-5).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n",
            "  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n",
            "  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n",
            "  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n",
            "  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n",
            "  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n",
            "  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n",
            "  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n",
            "  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n",
            "  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n",
            "  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n",
            "  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n",
            "  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n",
            "  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n",
            "  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n",
            "  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n",
            "  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n",
            "  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n",
            "  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n",
            "  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n",
            "  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n",
            "  cuda-visual-tools-11-1 default-jre dkms freeglut3 freeglut3-dev\n",
            "  keyboard-configuration libargon2-0 libcap2 libcryptsetup12\n",
            "  libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0 libjansson4\n",
            "  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n",
            "  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n",
            "  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n",
            "  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0 libxtst6\n",
            "  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n",
            "  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n",
            "  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n",
            "  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n",
            "  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n",
            "  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "![ -d $repository_name ] && echo \"Remove diretório antigo\" && rm -R $repository_name\n",
        "!git clone $repository_url\n",
        "\n",
        "!sudo apt install tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4-4zk2tFFaQ"
      },
      "source": [
        "# Analizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "id": "3jVtDFAzxsi1"
      },
      "outputs": [],
      "source": [
        "# Lista de nomes de arquivos ou diretórios para serem ignorados\n",
        "list_of_files_and_directories_to_ignore = ['.git']\n",
        "\n",
        "# dada uma string, retorna true se pelo menos um dos arquivos ou diretórios\n",
        "# que devem ser ignorados aparecem nela\n",
        "def should_ignore(name):\n",
        "  return True in [i in each for i in list_of_files_and_directories_to_ignore]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR0aLrZMLXGU",
        "outputId": "48a4a57e-4008-4bef-8157-7bcc50318708"
      },
      "outputs": [],
      "source": [
        "# Cria um arquivo contendo a quantidade de LOC por arquivo\n",
        "!find $repository_name | xargs wc -l > locarquivos.txt\n",
        "list_locs_of_files = !cat locarquivos.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataframe contendo os arquivos e seus respectivos commits\n",
        "df_files_from_db[['name', 'hash']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "J1fpEgViQbtC"
      },
      "outputs": [],
      "source": [
        "# calcula frequência dos arquivos em commits\n",
        "list_of_files_frequency_in_commits = {}\n",
        "\n",
        "# Dataframe agrupados por arquivos e seus commits\n",
        "df_groupby_name = df_files_from_db[['name', 'hash']].groupby('name')\n",
        "\n",
        "print(f'Quantidade de grupos: {df_groupby_name.ngroups}')\n",
        "print(f'Grupos: {df_groupby_name.groups}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "group_files = df_groupby_name.size()\n",
        "group_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_of_files_frequency_in_commits = group_files.to_dict()\n",
        "list_of_files_frequency_in_commits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "id": "JGS-R5ZZmci3"
      },
      "outputs": [],
      "source": [
        "# cria dicionário com o path de cada arquivo e LOC, ignorando aqueles que \n",
        "# não devem aparecer no json\n",
        "list_locs_of_files_updated = {}\n",
        "for each in list_locs_of_files[:-1]:\n",
        "  if not should_ignore(each):\n",
        "    elementos = each.split(' ') \n",
        "    list_locs_of_files_updated[elementos[-1]] = int(elementos[-2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "id": "BXqW_dcjlVVT"
      },
      "outputs": [],
      "source": [
        "# Lista todos os arquivos e diretorios\n",
        "list_of_files_and_directories = !cd $repository_name && tree -i -f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "id": "N5p4VORRE95U"
      },
      "outputs": [],
      "source": [
        "# Substitui o . pelo nome do repositório\n",
        "list_of_files_and_directories = [each.replace('./', repository_name + '/') for each in list_of_files_and_directories][1:-2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "id": "ixMuzQPKFEbD"
      },
      "outputs": [],
      "source": [
        "# remove os arquivos que devem ser ignorados\n",
        "list_of_files_and_directories_updated = []\n",
        "\n",
        "for each in list_of_files_and_directories:\n",
        "  if not should_ignore(each):\n",
        "    list_of_files_and_directories_updated.append(each)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "VglggomeieC0"
      },
      "outputs": [],
      "source": [
        "# classe que representa cada nó da árvore\n",
        "class Node:\n",
        "  def __init__(self, name = None, loc = None, heatmap = None, node_type = None, depth = None, children = []):\n",
        "    self.name = name\n",
        "    self.loc = loc\n",
        "    self.node_type = node_type\n",
        "    self.depth = depth\n",
        "    self.children = children\n",
        "    self.parent = None\n",
        "    self.heatmap = heatmap\n",
        "  \n",
        "  def append_node(self, node):\n",
        "    node.parent = self\n",
        "    self.children.append(node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "id": "ovShmR6ruXt9"
      },
      "outputs": [],
      "source": [
        "# preenchendo árvore com os arquivos e diretórios\n",
        "\n",
        "root = Node(name=repository_name, loc=0, heatmap=0, node_type=Type.DIR, depth=0, children=[])\n",
        "\n",
        "# lista auxiliar para controlar a profundidade da árvores\n",
        "# os nós são criados e inseridos como filhos do nó que está na última posição da lista\n",
        "nodes = [root]\n",
        "\n",
        "for key in list_of_files_and_directories_updated:\n",
        "  name = key.split('/')[-1] \n",
        "  depth = key.count('/')\n",
        "  loc = 0\n",
        "  heatmap = 0\n",
        "\n",
        "  if os.path.isdir(key):\n",
        "    key_type = Type.DIR\n",
        "    parent = os.path.dirname(key).split('/')[-1]\n",
        "  else:\n",
        "    key_type = Type.FILE\n",
        "    parent = str(Path(key).parent).split('/')[-1]\n",
        "    if key in list_locs_of_files_updated:\n",
        "      loc = list_locs_of_files_updated[key]\n",
        "    if name in list_of_files_frequency_in_commits:\n",
        "      heatmap = list_of_files_frequency_in_commits[name]\n",
        "  \n",
        "  # controle do último nó da lista auxiliar (onde deve ser inserido o nó atual)\n",
        "  if depth != len(nodes):\n",
        "    diff = abs(depth - len(nodes))\n",
        "    if depth < len(nodes):\n",
        "      for i in range(0, diff):\n",
        "        nodes.pop()\n",
        "    else:\n",
        "      nodes.append(node)\n",
        "\n",
        "  node = Node(name=name, loc=loc, heatmap=heatmap, node_type=key_type, depth=depth, children=[])\n",
        "\n",
        "  if len(nodes) > 0:\n",
        "    nodes[len(nodes) - 1].append_node(node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "id": "dYnznWT76izW"
      },
      "outputs": [],
      "source": [
        "# atualizar LOC de toda a árvore com base nas folhas\n",
        "def calculate_loc(node):\n",
        "  loc = 0\n",
        "  for each in node.children:\n",
        "    loc += each.loc + calculate_loc(each)\n",
        "  if len(node.children) > 0:\n",
        "    node.loc = loc\n",
        "  if node.parent is not None:\n",
        "    return loc\n",
        "\n",
        "# atualizar métrica do heatmap de toda a árvore com base nas folhas\n",
        "def calculate_heatmap(node):\n",
        "  heatmap = 0\n",
        "  for each in node.children:\n",
        "    heatmap += each.heatmap + calculate_heatmap(each)\n",
        "  if len(node.children) > 0:\n",
        "    node.heatmap = heatmap\n",
        "  if node.parent is not None:\n",
        "    return heatmap\n",
        "\n",
        "calculate_loc(root)\n",
        "calculate_heatmap(root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRpHaroDQPRK",
        "outputId": "fb96f68b-8dde-4e28-f95f-de411f4b92a7"
      },
      "outputs": [],
      "source": [
        "# mapeia árvore criada para o formato JSON\n",
        "\n",
        "def create_json_node(node):\n",
        "  return {\n",
        "    \"name\": node.name,\n",
        "    \"type\": node.node_type.name,\n",
        "    \"loc\": node.loc,\n",
        "    \"depth\": node.depth,\n",
        "    \"heatmap\": node.heatmap,\n",
        "    \"children\": []\n",
        "  }\n",
        "\n",
        "def traverse(node):\n",
        "  children = []\n",
        "  for each in node.children:\n",
        "    node = create_json_node(each)\n",
        "    children.append(node)\n",
        "    node[\"children\"] = traverse(each)\n",
        "  return children\n",
        "\n",
        "json_output = create_json_node(root)\n",
        "json_output[\"children\"] = traverse(root)\n",
        "\n",
        "print(json.dumps(json_output))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMowBZIwMdhaCrhVzn4vYpT",
      "include_colab_link": true,
      "name": "tests_json.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
